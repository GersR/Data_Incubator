---
title: "Comparison of Simple Kriging and Bayesian Kriging for apartment rent price prediction in some boroughs of México City"
output: html_document
---

The code of this work can be found [here](https://github.com/GersR/Data_Incubator). This is just a summary that sustains the idea behind these project.

```{r, echo=FALSE,results='hide',message=FALSE,warning=FALSE}
lapply(c('dplyr','maps','mapproj','rgeos','maptools','rgdal','sp','ggmap','ggplot2','knitr','akima','gstat','geoR','arm','corrplot','spBayes','fields','lsr','reshape','parallel'), require, character.only=T)
Sys.setlocale('LC_ALL','en_US.utf-8')
setwd("~/Dropbox/FInales/Final Tere")
```

# Data

We obtained the data from the webpage [propiedades.com](http://www.propiedades.com). We use the address of the apartment, bedrooms, bathrooms, half bathrooms, $m^2$  of the apartment, mantainance fee, rent price, if the rent price is in MXN or USD. We then clean the raw data 
and remove duplicates. After that we use the **ggmap** package to get latitude and longitude of the apartments (and at the same time we validate the address). Then we homologate the currency of the rent prices (MXN) and finally we do missing data imputation over the number of bathrooms and the $m^2$ because those values were missing in some of the apartments. 

The head of the data frame we use is as follows:

```{r,warning=FALSE,message=FALSE}
library(dplyr)
library(knitr)
datos <- readRDS('/Users/Gers/Dropbox/Data\ Incubator/Project/data/datos_finales.rds')

kable(datos %>%
        dplyr::select(dir,rec,banios.m,const.m,est,precio,lon,lat)%>%
        sample_n(20))
```

The plot of the apartmets over a map looks like these:

```{r,cache=TRUE,fig.align='center',warning=FALSE,message=FALSE}
datos <- readRDS('/Users/Gers/Dropbox/Data\ Incubator/Project/data/datos_finales.rds')

latq <- quantile(datos$lat,c(0.38))
lonq <- quantile(datos$lon,c(0.28))

df <- get_map(location = c(lonq,latq),
              maptype = 'roadmap', zoom = 12)

ggmap(df, extent = 'panel') + 
  geom_point(aes(x=lon,y=lat),colour = 'blue', alpha = 1,
             size = 2, data = datos)
```

#Exploratory data analysis

We want to look at the rent price dispersion over the addresses so we make the following graph:

```{r,fig.align='center',cache=TRUE,warning=FALSE,message=FALSE}
datos <- readRDS('/Users/Gers/Dropbox/Data\ Incubator/Project/data/datos_finales.rds')

qmplot(lon, lat, data=datos, 
       size=precio.c, alpha=I(0.8), color=precio_log,
       geom=c('point'), source='google')
```

That graph shows that, in fact, are some places where the most expensive apartments are concentrated. The idea is apply spatial models in these data so we make a graph of the level curves of the prices in order to look that there is a zone where the price of the apartments is higher and when you get far of that zone the rent prices get lower.

```{r,cache=TRUE,fig.align='center',warning=FALSE,message=FALSE}
fma <- precio_log ~ 1 + x + y + I(x*y) + I(x^2) + I(y^2) + 
  I(x^2*y) + I(x*y^2) + I(x^3) + I(y^3) 
mod.1 <- lm(formula = fma, data = datos)
summary(mod.1)

surf <- akima::interp(x=datos$x, y=datos$y, z=datos$precio_log, 
                      xo = seq(min(datos$x), max(datos$x), length = 50), 
                      yo = seq(min(datos$y), max(datos$y), length = 50),
                      linear = FALSE, extrap = TRUE,
                      duplicate = "median")

surf.r <- cbind(expand.grid(surf$x, surf$y), c(surf$z))
colnames(surf.r) <- c("x", "y", "z")
surf.r$z <- predict(mod.1, surf.r)
bks <- as.numeric(quantile(surf.r$z))
surf.r$pr <- as.factor(cut(surf.r$z,breaks = bks))
ggplot(surf.r, aes(x = x, y = y, z = z)) + 
  geom_tile(aes(fill = pr)) + 
  scale_fill_brewer(palette = "Blues") + 
  stat_contour()
```

With the previous graph we confirm that the apartment rent price gets lower as we go far of the Polanco zone; with these graph we also found that the rent prices are similar between closer apartments so fitting a spatial model seems right.

#Simple Kriging

```{r,cache=TRUE,warning=FALSE,message=FALSE}
datos_2 <- readRDS('/Users/Gers/Dropbox/Data\ Incubator/Project/data/datos_finales.rds')
datos_2$xx<-with(datos_2,x+media_lon)
datos_2$yy<-with(datos_2,y+media_lat)
```

We now proceed to the model. For these we used bathrooms, bedrooms, $m^2$ and parking spaces.

```{r,warning=FALSE,message=FALSE}
datos <- datos_2 %>% 
  dplyr::select(rec,banios.m,const.m,est,precio_log,x,y)

# Kriging

# Estimacion de la variación a gran escala
# Polinomio de tercer orden
fma <- precio_log ~ 1 + x + y + rec + banios.m + const.m + est
mod.1 <- lm(formula = fma, data = datos)
summary(mod.1)

# Estimacion de la variacion de pequeña escala
datos$mu_hat <- mod.1$fitted.values
datos <- mutate(datos, eta_hat = precio_log - mu_hat)

renta_datos <- data.frame(x = datos$x, y = datos$y, eta_hat = datos$eta_hat)
coordinates(renta_datos) = ~ x + y 
emp_variog <- variogram(eta_hat ~ 1, data = renta_datos, width = 0.001)
```

For the model we need to adjust the empirical semivariogram (we need it because it give us information about the average rate change of prices caused by the distance) in order to check spatial dependencies in the apartment rent prices. Alongside to the empirical semivariogram we plot the theoric semivariogram; for these we adjust an spheric semivariogram because we thought that the spatial dependence decreases approximately in linear form as the distance increases.  

```{r,fig.align='center',warning=FALSE,message=FALSE}
sph.variog <- function(sigma2, phi, tau2, dist){
  n <- length(dist)
  sph.variog.vec <- rep(0,n)
  for(i in 1:n){
    if(dist[i] < phi){
      sph.variog.vec[i] <- tau2 + (sigma2 * (((3 * dist[i]) / (2 * phi)) - 
                                               ((dist[i] ^ 3)/(2 * (phi ^ 3)))))
    }
    if(dist[i] >= phi){
      sph.variog.vec[i] <- tau2 + sigma2  
    }
  }
  return(sph.variog.vec)
}

sph_variog.w <- fit.variogram(emp_variog, 
                              vgm(psill= 0.05, model="Sph", range = 0.03, nugget = 0.1), 
                              fit.method = 7)
sigma2 <- sph_variog.w$psill[2]
phi <- sph_variog.w$range[2]
tau2 <- sph_variog.w$psill[1]
dist <- sph_variog.w$dist # vector de distancias


```

```{r,fig.height=6,fig.width=6,fig.align='center'}
dat <- data.frame(x = seq(0, 0.06, 0.0001), y = seq(0, 0.12, 0.0002))
ggplot(dat, aes(x = x, y = y)) +  ylim(0, 0.2) +
  labs(title = expression("Semi-variograma esférico ajustado"),
       x = "distancia", y = "semivarianza") +
  stat_function(fun = sph.variog, args = list(sigma2 = sigma2, phi = phi, tau2 = tau2),
                colour = "green3") + 
  geom_point(data = emp_variog,  aes(x = dist, y = gamma))
```

The Kriging model fitted is:

```{r}
# Estimacion de beta utilizando la matriz estimada de covarianzas
trend <- ~ 1 + datos$x + datos$y + datos$rec + 
  datos$banios.m + datos$const.m + datos$est
depas_geo <- as.geodata(obj = datos, coords.col = c(6, 7), data.col = 5)
```


```{r,cache=TRUE,warning=FALSE,message=FALSE,eval=FALSE}
depas_reml <- likfit(depas_geo, trend = trend, cov.model = "spherical", 
                     ini.cov.pars = c(sigma2, phi), nugget = tau2, 
                     fix.nugget = FALSE, lik.met = "REML")
saveRDS(depas_reml,'depas_reml.rds')
```

The $\beta$'s of the model are:

```{r,warning=FALSE,message=FALSE}
depas_reml <- readRDS('/Users/Gers/Dropbox/Data\ Incubator/Project/data/depas_reml.rds')
kable(depas_reml$beta)
kable(mod.1$coeff)
```

```{r,warning=FALSE,message=FALSE,cache=TRUE}
sigma2.reml <- depas_reml$sigmasq
phi.reml <- depas_reml$phi
tau2.reml <- depas_reml$tausq

#Kriging
kc.control <- krige.control(type.krige = "ok", 
                            trend.d = trend,
                            trend.l = trend, 
                            obj.model=depas_reml,
                            cov.model = "spherical",
                            cov.pars=c(sigma2.reml, phi.reml), 
                            nugget = tau2.reml)
loc <- matrix(c(datos$x,datos$y), nrow=nrow(datos), ncol=2)

#Prediccion
kc.sk.s0 <- krige.conv(depas_geo,
                       locations=loc,
                       krige=kc.control)
datos$ks_precio<-kc.sk.s0$predict
```

And the predictions obtained look like these:

```{r,fig.align='center',warning=FALSE,message=FALSE,cache=TRUE}
datos<- readRDS('/Users/Gers/Dropbox/Data\ Incubator/Project/data/datos_prediccion.rds')

datos$pks_precio.c <- quantileCut(datos$ks_precio,5)

ggplot(datos, aes(x = x, y = y, colour = pks_precio.c)) +
  geom_point(size = 2.3) +
  scale_colour_brewer(palette = "Blues")

mean_lon <--99.18264
mean_lat <- 19.41507

aux <- datos %>% 
  dplyr::select(x, y, ks_precio,pks_precio.c) %>%
  mutate(lon = x + mean_lon, lat= y + mean_lat )

qmplot(lon, lat, data=aux,
       size=pks_precio.c, alpha=I(0.8), color=ks_precio,
       geom=c('point'), source='google')
```

#Bayesian Kriging

We now proceed to the bayesian version of Kriging. For these we need priors for the sill, nugget and range. For the last two we use an Inverse-Gamma and for the sill we use a Uniform distribution. With the priors and the data we fit a model using 5000 iterations of the Monte Carlo method.

```{r,eval=FALSE,warning=FALSE,message=FALSE}
datos <- readRDS('/Users/Gers/Dropbox/Data\ Incubator/Project/data/datos_finales.rds') %>% 
  dplyr::select(rec,banios.m,const.m,est,precio_log,x,y)

N <- nrow(datos)
coords <- as.matrix(cbind(datos$x,datos$y),nrow=N,ncol=2)
Y <- datos$precio_log

Dist.mat <- rdist(coords)
max(Dist.mat)

# Valores iniciales
beta.ini <- rep(0,5)
sigma2.ini <- 1/rgamma(1,2,1)
tau2.ini <- 1/rgamma(1,2,0.5)
phi.ini <- runif(1,min=0.0008,max=0.06)

# Ajuste del modelo
fma <- Y ~ datos$x + datos$y + datos$rec + datos$banios.m +
  datos$const.m + datos$est
model.1 <- spLM(formula = fma, 
                coords=coords,starting=list("phi"=phi.ini,"sigma.sq"=sigma2.ini, "tau.sq"=tau2.ini),
                tuning=list("phi"=0.05, "sigma.sq"=0.1, "tau.sq"=0.05),
                priors=list("phi.Unif"=c(0.0008, 0.06), "sigma.sq.IG"=c(2, 1),
                            "tau.sq.IG"=c(2, 0.5)), cov.model="spherical",
                n.samples=5000, verbose=TRUE, n.report=100)
saveRDS(model.1,'model.rds')
```

```{r,warning=FALSE,message=FALSE,fig.align='center'}
model.1 <- readRDS('/Users/Gers/Dropbox/Data\ Incubator/Project/data/model.rds')
```

Algunas simulaciones de los parámetros de covarianza se ven así
```{r}
kable(model.1$p.theta.samples[1:5,])
```

The marignal posterior distribution of the parameters look like these:

```{r,message=FALSE,warning=FALSE,fig.align='center'}
# Graficas y resumen de la distribucion posterior marginal 
# de los parametros de covarianza
plot(model.1$p.theta.samples)
print(summary(model.1$p.theta.samples[1001:5000,]))
print(summary(model.1$p.theta.samples[1001:5000,]))
```

The 95% probability intervals of the parameters look like these:
```{r}
# Intervalo de 95% de probabilidad para parametros de covarianza
apply(model.1$p.theta.samples[1001:5000,],2,quantile,c(0.025,0.975))
```

```{r,eval=FALSE,message=FALSE,warning=FALSE}
# Recuperar coeficientes de estimacion con burning de 1000
model.1.recov <- spRecover(model.1, start=1000, verbose=TRUE)
saveRDS(model.1.recov, 'model.1.recov.rds')
```

The marginal posterior probability of the $\beta$ coefficients looks like these:

```{r,fig.align='center',cache=TRUE}
model.1.recov <- readRDS('/Users/Gers/Dropbox/Data\ Incubator/Project/data/model.1.recov.rds')

# Graficas y resumenes de la distribucion marginal posterior
# de los coeficientes beta (parametros de regresion)
plot(model.1.recov$p.beta.recover.samples[,1:3])
plot(model.1.recov$p.beta.recover.samples[,4:5])
plot(model.1.recov$p.beta.recover.samples[,6:7])
summary(model.1.recov$p.beta.recover.samples)

# eta prima 
eta.hat <- t(model.1.recov$p.w.recover.samples)

model.1.eta.summary <- summary(mcmc(t(model.1.recov$p.w.recover.samples)))$quantiles[,c(3,1,5)]
  model.1.eta.summary[1:5,]
```

We now proceed to the predictions:

```{r,eval=FALSE,message=FALSE,warning=FALSE}
# Hacemos la prediccion
# Matriz de covariables
predcov <- matrix(cbind(rep(1,N),datos$x,datos$y,datos$rec,
                        datos$banios.m,datos$const.m,datos$est),
                        nrow=N,ncol=7)
# Utiliza muestreo por composicion con MCMC a partir de 
# la distribucion predictiva a posteriori
# El burning es de 1000 muestras y se hacen predicciones cada
# dos muestras (parametro thin)
pred <- spPredict(model.1, 
                  pred.coords=coords, 
                  pred.covars=predcov,
                  start=1000,
                  thin=2)
saveRDS(pred, 'pred.rds')
```

We obtain the posterior mean of the predictions:

```{r,cache=TRUE}
pred <- readRDS('/Users/Gers/Dropbox/Data\ Incubator/Project/data/pred.rds')
str(pred$p.y.predictive.samples)

## Media posterior de las predicciones. 
post.pred.mean <- rowMeans(pred$p.y.predictive.samples)
(post.pred.mean[1:10])
```


```{r,warning=FALSE,message=FALSE,cache=TRUE}
# Predicciones de kriging
datos <- readRDS('/Users/Gers/Dropbox/Data\ Incubator/Project/data/datos_finales.rds')
datos_pred <- readRDS('/Users/Gers/Dropbox/Data\ Incubator/Project/data/datos_prediccion.rds')

# Regresion lineal
fma <- precio_log ~ 1 + x + y + rec + banios.m + const.m + est
mod.1 <- lm(formula = fma, data = datos)
summary(mod.1)


# Predicciones de kriging bayesiano
N <- 8100
xo <- seq(min(datos$x), max(datos$x), length = 90)
yo <- seq(min(datos$y), max(datos$y), length = 90)
grid <- akima::interp(x=datos$x, y=datos$y, z=datos$precio_log, 
                      xo = xo, yo = yo,
                      linear = FALSE, extrap = TRUE,
                      duplicate = "median")
grid <- cbind(expand.grid(grid$x, grid$y), c(grid$z))
colnames(grid) <- c('x','y','z')
coords <- grid[,c('x','y')]
predcov <- matrix(cbind(rep(1,N),coords$x,coords$y,
                        sample(datos$rec,N,replace=T),
                        sample(datos$banios.m,N,replace=T),
                        rgamma(N,2.62,0.017),
                        sample(datos$est,N,replace=T)),
                  nrow=N,ncol=7)

model.1 <- readRDS('/Users/Gers/Dropbox/Data\ Incubator/Project/data/model.rds')
model.0 <- readRDS('/Users/Gers/Dropbox/Data\ Incubator/Project/data/depas_reml.rds')
sigma2.reml <- model.0$sigmasq
phi.reml <- model.0$phi
tau2.reml <- model.0$tausq
trend <- ~ 1 + datos$x + datos$y + datos$rec + 
  datos$banios.m + datos$const.m + datos$est
depas_geo <- as.geodata(obj = datos, coords.col = c(20, 21), data.col = 22)
trend_pred <- ~ 1 + coords$x + coords$y + predcov[,4] + 
  predcov[,5] + predcov[,6] + predcov[,7]
kc.control <- krige.control(type.krige = "ok", 
                            trend.d = trend,
                            trend.l = trend_pred, 
                            obj.model = model.0,
                            cov.model = "spherical",
                            cov.pars=c(sigma2.reml, phi.reml), 
                            nugget = tau2.reml)

kc.sk.s0 <- krige.conv(depas_geo,
                       locations=coords,
                       krige=kc.control)
pred_ok_media <- kc.sk.s0$predict
pred_ok_var <- kc.sk.s0$krige.var
```

And with all that we can make the next plots:
```{r,message=FALSE,warning=FALSE,eval=FALSE}
pred_grid_bayesiano <- spPredict(model.1, 
                  pred.coords=coords, 
                  pred.covars=predcov,
                  start=500,
                  thin=10)

saveRDS(pred_grid_bayesiano,'pred_grid_bayesiano.rds')
```

```{r,message=FALSE,warning=FALSE,fig.align='center',cache=TRUE}
N <- 8100
pred_grid_bayesiano <- readRDS('/Users/Gers/Dropbox/Data\ Incubator/Project/data/pred_grid_bayesiano.rds')
post_pred_bayesiano <- rowMeans(pred_grid_bayesiano$p.y.predictive.samples)
post_pred_95ci_bayes<-t(apply(pred_grid_bayesiano$p.y.predictive.samples,1,quantile,c(0.25,0.975)))
dat <- data.frame(id=1:N,media=post_pred_bayesiano,post_pred_95ci_bayes)
dat <- cbind(dat,predcov)
colnames(dat)<-c('id','media','lb_bayes','ub_bayes','int','x','y','rec','banios','const','est')
dat$lon <- dat$x + mean_lon
dat$lat <- dat$y + mean_lat
dat$ks_precio<-kc.sk.s0$predict

lonq <- median(dat$lon)
latq <- median(dat$lat)
```


```{r,eval=FALSE}
df <- get_map(location = c(lonq,latq),
              maptype = 'roadmap', zoom = 13)
saveRDS(df,'df.rds')
```


```{r,cache=TRUE,fig.align='center',warning=FALSE,message=FALSE,fig.height=8,fig.width=8}
df <- readRDS('/Users/Gers/Dropbox/Data\ Incubator/Project/data/df.rds')
ggmap(df, extent = 'panel') +
  geom_tile(data = dat,aes(x = lon, y = lat, z = media,
                fill = media, alpha=1)) +
  stat_contour(data=dat,aes(z = media),binwidth=10,size=0.5)+ 
  scale_fill_gradient2(low = "#0000FF", mid = "#FFFFFF", high ="#FF0000", 
                       midpoint = median(dat$media), space = "rgb", guide = "colourbar")
```


```{r,cache=TRUE,warning=FALSE,fig.align='center',message=FALSE,fig.height=8,fig.width=8}
qmplot(lon, lat, data=dat,
       size=media, alpha=I(0.5), color=media,
       geom=c('point'), source='google') +
  scale_color_gradient(low='pink', high='red')
```

In both of the previous plots we notice that the Polanco and surrounding areas has a higher mean rent price and as you go away the rent price gets lower.

### Comparison between Simple Kriging and Bayesian Kriging predictions

```{r,cache=TRUE,warning=FALSE,fig.align='center',message=FALSE}
# Agregamos los intervalos de prediccion de kriging ordinario
dat$pred_ok <- pred_ok_media
dat$lb_ok <- pred_ok_media - 2*sqrt(pred_ok_var)
dat$ub_ok <- pred_ok_media + 2*sqrt(pred_ok_var)

ggplot(dat[sample(1:nrow(dat),100),]) + 
  geom_pointrange(aes(x = id, y=pred_ok, 
                      ymin=lb_ok, ymax=ub_ok), color='red')+
  geom_pointrange(aes(x = id, y=media, 
                      ymin=lb_bayes, ymax=ub_bayes), color='blue') 
```

In the previous graph we can see that the intervals of prediction between the models are similar but, in general, the probability confidence intervals of the bayesian prediction are smaller.



